# ğŸ“Š Daily Sales Data Pipeline with Airflow, Snowflake, and dbt

An ETL/ELT pipeline for **retail supply chain analytics**, built with:

- **Apache Airflow** â†’ workflow orchestrator  
- **Snowflake** â†’ main data warehouse  
- **dbt (data build tool)** â†’ transformation, snapshotting, testing  
- **MySQL** â†’ operational database as the data source  

---

## ğŸš€ Key Features
- Automated schema and table creation in Snowflake  
- Extract data from MySQL (dimension & fact tables)  
- Load data into the *landing* schema in Snowflake using **Pandas + SQLAlchemy**  
- Modular pipeline (`extract.py`, `load.py`, `connection.py`, etc.) â†’ easy to maintain  
- Configurable via **Airflow Variables** (`secret_file`, `sql_file`, etc.)  
- **dbt tasks** automatically executed in a single task group:
  - `test_source` â†’ validate sources  
  - `run` â†’ run transformations  
  - `test_model` â†’ test model outputs  
  - `snapshot` â†’ perform snapshotting  

---

## ğŸ“‚ Struktur Proyek

.
â”œâ”€â”€ dags/
â”‚ â””â”€â”€ daily_sales.py 
â”œâ”€â”€ include/
â”‚ â”œâ”€â”€ config/
â”‚ â”‚ â”œâ”€â”€ .secrets.toml 
â”‚ â”‚ â””â”€â”€ airflow_settings.yaml
â”‚ â”œâ”€â”€ etl/
â”‚ â”‚ â”œâ”€â”€ connection.py 
â”‚ â”‚ â”œâ”€â”€ extract.py 
â”‚ â”‚ â”œâ”€â”€ load.py 
â”‚ â”‚ â”œâ”€â”€ transform.py
â”‚ â”‚ â””â”€â”€ utils.py 
â”‚ â””â”€â”€ sql/
â”‚   â””â”€â”€ create_table.sql
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ dags/
â”‚   â””â”€â”€ test_dag_example.py
â”‚
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.override.yml
â”œâ”€â”€ dockerfile
â”œâ”€â”€ packages.txt
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ How It Works
- **Airflow DAG** (`daily_sales.py`) orchestrates the pipeline:
    - Creates schemas/tables in Snowflake
    - Extracts data from MySQL
    - Loads raw data into Snowflake (landing schema)
    - Executes dbt tasks for transformation, testing, and snapshotting
- **Configuration** is managed via:
    - Airflow Variables (paths & secrets)
    - .secrets.toml for credentials (not committed to Git)
- **dbt Project** handles transformations and quality checks, ensuring data is production-ready.

---

## ğŸ› ï¸ Tech Stack

- Airflow `2.x`
- Snowflake
- dbt Core `1.x`
- MySQL
- Python `3.9+`
- Pandas + SQLAlchemy

---


